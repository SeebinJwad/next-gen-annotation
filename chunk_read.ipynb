{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7da40a0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T14:33:07.099686Z",
     "start_time": "2021-07-26T14:33:07.076689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import os\n",
    "import numpy as np\n",
    "import _pickle as cpickle\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f249b05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T14:39:25.897734Z",
     "start_time": "2021-07-26T14:39:25.878135Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pickle_chr(pickle_filename, db_filename, chunksize):\n",
    "    # remove previous pickle file if exists\n",
    "    if os.path.exists(pickle_filename): os.remove(pickle_filename) \n",
    "    # wb+ to ensure previous pkl files of same name arent appended to\n",
    "    with open(pickle_filename,'wb+') as file:\n",
    "        for chunk in pd.read_csv(db_filename, engine='c', sep='\\t', usecols=[0], index_col=False, na_values=None, dtype={'#CHROM:':'string'}, chunksize=chunksize): \n",
    "            cpickle.dump(chunk, file)\n",
    "# {\"#CHROM\":\"category\"}\n",
    "# open pickle file --> for each chunk in database's chr column: dump the chunk into pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb9e1ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T14:39:26.040158Z",
     "start_time": "2021-07-26T14:39:26.015163Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pickle_val(pickle_filename, db_filename, val_cols, dtypes, chunksize):\n",
    "    if os.path.exists(pickle_filename): os.remove(pickle_filename) \n",
    "    with open(pick_filename, 'wb+') as file:\n",
    "        for chunk in pd.read_csv(db_filename, engine='c', sep='\\t', usecols=valcols, index_col=False, dtype=dtypes, chunksize=chunksize): \n",
    "            cpickle.dump(chunk,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165cca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T14:50:36.092827Z",
     "start_time": "2021-07-26T14:49:22.694774Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# def chr_idx(database, chr_raw, chunksize=10**4):\n",
    "# chr_raw True == chr1...chrY, chr_raw false == 1...Y\n",
    "# database = 'gene4denovo201907'\n",
    "database = \"gnomad211_exome\"\n",
    "chunksize = 10 ** 4\n",
    "\n",
    "pickle_chr('%s.pkl' % database, 'databases/hg38_%s.txt' % database, chunksize)\n",
    "\n",
    "chromosome_list = [x+1 for x in range(22)] + [\"X\", \"Y\"]\n",
    "# [\"chr\" + str(x+1) for x in range(22)] + [\"chrX\", \"chrY\"]  \n",
    "\n",
    "total_chr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2573e203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T14:52:03.721320Z",
     "start_time": "2021-07-26T14:51:57.693420Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with open(\"%s.pkl\" % database, 'rb') as file:\n",
    "    curr_chr = 0 # counts until last index of chromosome list\n",
    "    chunk_counter = 0 # multiply by chunk size to get actual - not relative - index\n",
    "    while True:\n",
    "        try:\n",
    "            result = cpickle.load(file)\n",
    "            chunk = pd.Series(dtype=\"category\")\n",
    "            chunk = result\n",
    "            del result\n",
    "        # EOFError when last chunk has size < chunk size\n",
    "        except EOFError:\n",
    "            break\n",
    "        else:\n",
    "            # if last value of chunk is next chr, find where index of next chr is\n",
    "            curr_chunk_idx = chunksize * chunk_counter\n",
    "            try:\n",
    "                next_chr = chromosome_list[curr_chr + 1]\n",
    "            except IndexError:\n",
    "                ...\n",
    "            if chunk.iloc[-1][0] == next_chr:\n",
    "                print(chunk.describe())#.iloc[3][0])) # + curr_chunk_idx))\n",
    "                curr_chr += 1\n",
    "            chunk_counter += 1\n",
    "            del chunk\n",
    "#x = chr_idx(\"gnomad211_exome\", chr_raw=True, chunksize=10 ** 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f31c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T15:18:23.727439Z",
     "start_time": "2021-07-26T15:18:23.547096Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# splitter = np.random.choice([0, 1, 2], 10 ** 4)\n",
    "\n",
    "with open(\"gnomad211_exome.pkl\", 'rb') as file:\n",
    "    # load file up until x, y\n",
    "    result = cpickle.load(file)\n",
    "    chromosome_list = [str(x+1) for x in range(22)] + [\"X\", \"Y\"]\n",
    "    chunk = pd.Series(pd.Categorical.from_codes(result, categories=chromosome_list))\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b70a38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T15:18:23.727439Z",
     "start_time": "2021-07-26T15:18:23.547096Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with open(\"exac03_chr1.pkl\", 'wb+') as file:\n",
    "    for chunk in pd.read_csv(\"databases/hg38_exac03.txt\", nrows=1089537,engine='c', sep='\\t', usecols=[1,5,6,7,8,9,10,11,12], index_col=\"Start\", dtype={\"Start\":\"int\",\"ExAC_ALL\":\"float\",\"ExAC_AFR\":\"float\",\"ExAC_AMR\":\"float\",\"ExAC_EAS\":\"float\",\"ExAC_FIN\":\"float\",\"ExAC_NFE\":\"float\",\"ExAC_OTH\":\"float\",\"ExAC_SAS\":\"float\"}, na_values=\".\", chunksize=10**4): \n",
    "        cpickle.dump(chunk,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25d75a04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T20:15:26.065978Z",
     "start_time": "2021-07-26T20:15:25.030281Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"databases/hg38_gene4denovo201907.txt\", sep='\\t', usecols=[1,5,6,7,8,9,10], index_col=\"POS\", dtype={\"POS\":\"int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e03a54d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T20:15:27.360445Z",
     "start_time": "2021-07-26T20:15:27.344448Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DN ID                                 dn326360\n",
       "Patient ID                               14458\n",
       "Phenotype                                  ASD\n",
       "Platform                                   WGS\n",
       "Study         Joon-Yong An et al. Science 2018\n",
       "Pubmed ID                             30545852\n",
       "Name: 71120533, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[15208]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
